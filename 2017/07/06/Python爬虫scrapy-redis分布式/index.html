<!DOCTYPE html>
<html>
  
<head>
  <meta charset="utf-8">
  <meta name="author" content="Dong Yuanxin" />
  
  
  <title>Python爬虫scrapy-redis分布式 | GaryMarine</title>

  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

  
    <meta name="keywords" content="Python,scrapy-redis," />
  

  
  <meta name="description" content="董沅鑫的小站">

  

  <script src="//cdn.jsdelivr.net/npm/leancloud-storage@3.11.1/dist/av-min.js" async></script>

  
    <script type="text/javascript" src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script>
  

  
    <script src="//unpkg.com/valine/dist/Valine.min.js" async></script>
  

  <script>
  // theme-ad's config script
  // it can be used in every script
  
  window.AD_CONFIG = {
    leancloud: {"appid":"Hyq9wkH495DgNHWhDQCOfQSp-gzGzoHsz","appkey":"WaR7nrzhliHj9aVwdQzkdlGd","comment":true,"count":true},
    welcome: {"enable":true,"interval":"wfw"},
    start_time: "2018-02-10",
    passwords: ["9fd4703ff67642ec7fc0f8616d7513e620263fa6f3758b5836f496dfe334ae34", ],
    is_post: true,
    lock: false,
    author: "Dong Yuanxin",
    share: {"twitter":true,"facebook":true,"weibo":true,"qq":true,"wechat":true},
    mathjax: true
  };
</script>

  <script src="/vendor/sha256.min.js"></script>
<script src="/js/auth.js"></script>
<script src="/js/index.js"></script>
<script src="/vendor/qrcode.min.js"></script>

  
    <link rel="icon" href="/images/favicon.ico">
    <link rel="apple-touch-icon" href="/images/touch-icon.png">
  

  <link href="//netdna.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet">

  <link rel="stylesheet" href="/css/index.css">
<link rel="stylesheet" href="/styles/components/highlight/highlight.css">

  

  



</head>
  <body>
    <header class="site-header">
  <div class="site-header-brand">
    
      <span class="site-header-brand-title">
        <a href="/">YuanXin</a>
      </span>
    
    
      <span class="site-header-brand-motto"> | 归来仍是少年</span>
    
  </div>
  <div class="site-header-right">
    <nav class="site-header-navigation">
      
        <a href="/" target="_self">首页</a>
      
        <a href="/archives/" target="_self">归档</a>
      
        <a href="/tags/" target="_self">标签</a>
      
        <a href="/categories/" target="_self">分类</a>
      
        <a href="/friends/" target="_self">友链</a>
      
        <a href="/about/" target="_self">关于</a>
      
    </nav>
    <div class="site-header-btn">
      
        <a href="https://github.com/dongyuanxin/" target="_blank">
          <i class="fa fa-github-alt"></i>
        </a>
      
      <a href="javascript:void(0);" id="site-search">
        <i class="fa fa-search"></i>
      </a>
    </div>
  </div>
</header>
<div id="site-process"></div>
    <main>
      
  <div class="passage">
  <div class="passage-meta">
    <span>
      <i class="fa fa-calendar"></i>2017-07-06
    </span>
    
      <span>
        | <a href="/categories/Python/"><i class="fa fa-bookmark"></i>Python</a>
      </span>
    
    
      <span>
        | <i class="fa fa-unlock-alt"></i>UNLOCK
      </span>
    
  </div>
  <h1 class="passage-title">
    Python爬虫scrapy-redis分布式
  </h1>
  
  <article class="passage-article">
    <h1 id="Python爬虫scrapy-redis分布式"><a href="#Python爬虫scrapy-redis分布式" class="headerlink" title="Python爬虫scrapy-redis分布式"></a>Python爬虫scrapy-redis分布式</h1><p><strong>目标任务：将之前新浪网的Scrapy爬虫项目，修改为基于RedisSpider类的scrapy-redis分布式爬虫项目，将数据存入redis数据库。</strong></p>
<p><strong>一、item文件，和之前项目一样不需要改变</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line">reload(sys)</span><br><span class="line">sys.setdefaultencoding(<span class="string">"utf-8"</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SinanewsItem</span><span class="params">(scrapy.Item)</span>:</span></span><br><span class="line">    <span class="comment"># 大类的标题和url</span></span><br><span class="line">    parentTitle = scrapy.Field()</span><br><span class="line">    parentUrls = scrapy.Field()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 小类的标题和子url</span></span><br><span class="line">    subTitle = scrapy.Field()</span><br><span class="line">    subUrls = scrapy.Field()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 小类目录存储路径</span></span><br><span class="line">    subFilename = scrapy.Field()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 小类下的子链接</span></span><br><span class="line">    sonUrls = scrapy.Field()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 文章标题和内容</span></span><br><span class="line">    head = scrapy.Field()</span><br><span class="line">    content = scrapy.Field()</span><br></pre></td></tr></table></figure>
<p><strong>二、spiders爬虫文件，使用RedisSpider类替换之前的Spider类，其余地方做些许改动即可，具体代码如下：</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> sinaNews.items <span class="keyword">import</span> SinanewsItem</span><br><span class="line"><span class="keyword">from</span> scrapy_redis.spiders <span class="keyword">import</span> RedisSpider</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line">reload(sys)</span><br><span class="line">sys.setdefaultencoding(<span class="string">"utf-8"</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SinaSpider</span><span class="params">(RedisSpider)</span>:</span></span><br><span class="line">    name = <span class="string">"sina"</span></span><br><span class="line">    <span class="comment"># 启动爬虫的命令</span></span><br><span class="line">    redis_key = <span class="string">"sinaspider:strat_urls"</span></span><br><span class="line">　　<span class="comment"># 动态定义爬虫爬取域范围</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, *args, **kwargs)</span>:</span></span><br><span class="line">        domain = kwargs.pop(<span class="string">'domain'</span>, <span class="string">''</span>)</span><br><span class="line">        self.allowed_domains = filter(<span class="keyword">None</span>, domain.split(<span class="string">','</span>))</span><br><span class="line">        super(SinaSpider, self).__init__(*args, **kwargs)</span><br><span class="line">      </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span><span class="params">(self, response)</span>:</span></span><br><span class="line">        items= []</span><br><span class="line">        <span class="comment"># 所有大类的url 和 标题</span></span><br><span class="line">        parentUrls = response.xpath(<span class="string">'//div[@id="tab01"]/div/h3/a/@href'</span>).extract()</span><br><span class="line">        parentTitle = response.xpath(<span class="string">'//div[@id="tab01"]/div/h3/a/text()'</span>).extract()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 所有小类的ur 和 标题</span></span><br><span class="line">        subUrls  = response.xpath(<span class="string">'//div[@id="tab01"]/div/ul/li/a/@href'</span>).extract()</span><br><span class="line">        subTitle = response.xpath(<span class="string">'//div[@id="tab01"]/div/ul/li/a/text()'</span>).extract()</span><br><span class="line"></span><br><span class="line">        <span class="comment">#爬取所有大类</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>, len(parentTitle)):</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 爬取所有小类</span></span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="number">0</span>, len(subUrls)):</span><br><span class="line">                item = SinanewsItem()</span><br><span class="line"></span><br><span class="line">                <span class="comment"># 保存大类的title和urls</span></span><br><span class="line">                item[<span class="string">'parentTitle'</span>] = parentTitle[i]</span><br><span class="line">                item[<span class="string">'parentUrls'</span>] = parentUrls[i]</span><br><span class="line"></span><br><span class="line">                <span class="comment"># 检查小类的url是否以同类别大类url开头，如果是返回True (sports.sina.com.cn 和 sports.sina.com.cn/nba)</span></span><br><span class="line">                if_belong = subUrls[j].startswith(item[<span class="string">'parentUrls'</span>])</span><br><span class="line"></span><br><span class="line">                <span class="comment"># 如果属于本大类，将存储目录放在本大类目录下</span></span><br><span class="line">                <span class="keyword">if</span>(if_belong):</span><br><span class="line">                    </span><br><span class="line">                    <span class="comment"># 存储 小类url、title和filename字段数据</span></span><br><span class="line">                    item[<span class="string">'subUrls'</span>] = subUrls[j]</span><br><span class="line">                    item[<span class="string">'subTitle'</span>] =subTitle[j]</span><br><span class="line">                    items.append(item)</span><br><span class="line"></span><br><span class="line">        <span class="comment">#发送每个小类url的Request请求，得到Response连同包含meta数据 一同交给回调函数 second_parse 方法处理</span></span><br><span class="line">        <span class="keyword">for</span> item <span class="keyword">in</span> items:</span><br><span class="line">            <span class="keyword">yield</span> scrapy.Request( url = item[<span class="string">'subUrls'</span>], meta=&#123;<span class="string">'meta_1'</span>: item&#125;, callback=self.second_parse)</span><br><span class="line"></span><br><span class="line">    <span class="comment">#对于返回的小类的url，再进行递归请求</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">second_parse</span><span class="params">(self, response)</span>:</span></span><br><span class="line">        <span class="comment"># 提取每次Response的meta数据</span></span><br><span class="line">        meta_1= response.meta[<span class="string">'meta_1'</span>]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 取出小类里所有子链接</span></span><br><span class="line">        sonUrls = response.xpath(<span class="string">'//a/@href'</span>).extract()</span><br><span class="line"></span><br><span class="line">        items= []</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>, len(sonUrls)):</span><br><span class="line">            <span class="comment"># 检查每个链接是否以大类url开头、以.shtml结尾，如果是返回True</span></span><br><span class="line">            if_belong = sonUrls[i].endswith(<span class="string">'.shtml'</span>) <span class="keyword">and</span> sonUrls[i].startswith(meta_1[<span class="string">'parentUrls'</span>])</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 如果属于本大类，获取字段值放在同一个item下便于传输</span></span><br><span class="line">            <span class="keyword">if</span>(if_belong):</span><br><span class="line">                item = SinanewsItem()</span><br><span class="line">                item[<span class="string">'parentTitle'</span>] =meta_1[<span class="string">'parentTitle'</span>]</span><br><span class="line">                item[<span class="string">'parentUrls'</span>] =meta_1[<span class="string">'parentUrls'</span>]</span><br><span class="line">                item[<span class="string">'subUrls'</span>] = meta_1[<span class="string">'subUrls'</span>]</span><br><span class="line">                item[<span class="string">'subTitle'</span>] = meta_1[<span class="string">'subTitle'</span>]</span><br><span class="line">                item[<span class="string">'sonUrls'</span>] = sonUrls[i]</span><br><span class="line">                items.append(item)</span><br><span class="line"></span><br><span class="line">        <span class="comment">#发送每个小类下子链接url的Request请求，得到Response后连同包含meta数据 一同交给回调函数 detail_parse 方法处理</span></span><br><span class="line">        <span class="keyword">for</span> item <span class="keyword">in</span> items:</span><br><span class="line">                <span class="keyword">yield</span> scrapy.Request(url=item[<span class="string">'sonUrls'</span>], meta=&#123;<span class="string">'meta_2'</span>:item&#125;, callback = self.detail_parse)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 数据解析方法，获取文章标题和内容</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">detail_parse</span><span class="params">(self, response)</span>:</span></span><br><span class="line">        item = response.meta[<span class="string">'meta_2'</span>]</span><br><span class="line">        content = <span class="string">""</span></span><br><span class="line">        head = response.xpath(<span class="string">'//h1[@id="main_title"]/text()'</span>)</span><br><span class="line">        content_list = response.xpath(<span class="string">'//div[@id="artibody"]/p/text()'</span>).extract()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 将p标签里的文本内容合并到一起</span></span><br><span class="line">        <span class="keyword">for</span> content_one <span class="keyword">in</span> content_list:</span><br><span class="line">            content += content_one</span><br><span class="line"></span><br><span class="line">        item[<span class="string">'head'</span>]= head[<span class="number">0</span>] <span class="keyword">if</span> len(head) &gt; <span class="number">0</span> <span class="keyword">else</span> <span class="string">"NULL"</span></span><br><span class="line">        item[<span class="string">'content'</span>]= content</span><br><span class="line"></span><br><span class="line">        <span class="keyword">yield</span> item</span><br></pre></td></tr></table></figure>
<p><strong>三、settings文件设置</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">SPIDER_MODULES = [<span class="string">'sinaNews.spiders'</span>]</span><br><span class="line">NEWSPIDER_MODULE = <span class="string">'sinaNews.spiders'</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用scrapy-redis里的去重组件，不使用scrapy默认的去重方式</span></span><br><span class="line">DUPEFILTER_CLASS = <span class="string">"scrapy_redis.dupefilter.RFPDupeFilter"</span></span><br><span class="line"><span class="comment"># 使用scrapy-redis里的调度器组件，不使用默认的调度器</span></span><br><span class="line">SCHEDULER = <span class="string">"scrapy_redis.scheduler.Scheduler"</span></span><br><span class="line"><span class="comment"># 允许暂停，redis请求记录不丢失</span></span><br><span class="line">SCHEDULER_PERSIST = <span class="keyword">True</span></span><br><span class="line"><span class="comment"># 默认的scrapy-redis请求队列形式（按优先级）</span></span><br><span class="line">SCHEDULER_QUEUE_CLASS = <span class="string">"scrapy_redis.queue.SpiderPriorityQueue"</span></span><br><span class="line"><span class="comment"># 队列形式，请求先进先出</span></span><br><span class="line"><span class="comment">#SCHEDULER_QUEUE_CLASS = "scrapy_redis.queue.SpiderQueue"</span></span><br><span class="line"><span class="comment"># 栈形式，请求先进后出</span></span><br><span class="line"><span class="comment">#SCHEDULER_QUEUE_CLASS = "scrapy_redis.queue.SpiderStack"</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 只是将数据放到redis数据库，不需要写pipelines文件</span></span><br><span class="line">ITEM_PIPELINES = &#123;</span><br><span class="line"><span class="comment">#    'Sina.pipelines.SinaPipeline': 300,</span></span><br><span class="line">    <span class="string">'scrapy_redis.pipelines.RedisPipeline'</span>: <span class="number">400</span>,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># LOG_LEVEL = 'DEBUG'</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Introduce an artifical delay to make use of parallelism. to speed up the</span></span><br><span class="line"><span class="comment"># crawl.</span></span><br><span class="line">DOWNLOAD_DELAY = <span class="number">1</span></span><br><span class="line"><span class="comment"># 指定数据库的主机IP</span></span><br><span class="line">REDIS_HOST = <span class="string">"192.168.13.26"</span></span><br><span class="line"><span class="comment"># 指定数据库的端口号</span></span><br><span class="line">REDIS_PORT = <span class="number">6379</span></span><br></pre></td></tr></table></figure>
<p><strong>执行命令：</strong></p>
<p><strong>本次直接使用本地的redis数据库，将settings文件中的REDIS_HOST和REDIS_PORT注释掉。</strong></p>
<p><strong>启动爬虫程序</strong></p>
<figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="selector-tag">scrapy</span> <span class="selector-tag">runspider</span> <span class="selector-tag">sina</span><span class="selector-class">.py</span></span><br></pre></td></tr></table></figure>
<p><strong>表示程序处于等待状态，此时在redis数据库端执行如下命令：</strong></p>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">redis-cli&gt; lpush sinaspider:start_urls http://news.sina.com.cn/guide/</span><br></pre></td></tr></table></figure>
<p><strong><a href="http://news.sina.com.cn/guide/为起始url，此时程序开始执行。" target="_blank" rel="noopener">http://news.sina.com.cn/guide/为起始url，此时程序开始执行。</a></strong></p>
  </article>
  <aside class="table-content" id="site-toc">
  <div class="table-content-title">
    <i class="fa fa-arrow-right fa-lg" id="site-toc-hide-btn"></i>
    <span>目录</span>
  </div>
  <div class="table-content-main">
    <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Python爬虫scrapy-redis分布式"><span class="toc-text">Python爬虫scrapy-redis分布式</span></a></li></ol>
  </div>
</aside>
  
    <div class="passage-tags">
     
      <a href="/tags/scrapy-redis/"><i class="fa fa-tags"></i>scrapy-redis</a>
    
    </div>
  
</div>

    </main>
    
      <div class="site-comment-contanier">
  <p id="site-comment-info">
    <i class="fa fa-spinner fa-spin"></i> 评论加载中
  </p>
  <div id="site-comment">
  </div>
</div>
    
    <div class="site-footer-wrapper">
  <footer class="site-footer">
    
      <div class="site-footer-col">
        <h5 class="site-footer-title">博客推荐</h5>
        
          <span class="site-footer-item">
            <a href="https://godbmw.com/" target="_blank">GodBMW</a>
          </span>
        
          <span class="site-footer-item">
            <a href="http://ruanyifeng.com/" target="_blank">阮一峰的个人网站</a>
          </span>
        
          <span class="site-footer-item">
            <a href="https://www.liaoxuefeng.com/" target="_blank">廖雪峰的官方网站</a>
          </span>
        
      </div>
    
      <div class="site-footer-col">
        <h5 class="site-footer-title">系列教程</h5>
        
          <span class="site-footer-item">
            <a href="https://godbmw.com/categories/webpack4%E7%B3%BB%E5%88%97%E6%95%99%E7%A8%8B/" target="_blank">webpack4系列教程</a>
          </span>
        
          <span class="site-footer-item">
            <a href="https://godbmw.com/design-patterns/" target="_blank">设计模式手册</a>
          </span>
        
          <span class="site-footer-item">
            <a href="https://godbmw.com/leetcode/" target="_blank">Leetcode解题报告</a>
          </span>
        
      </div>
    
      <div class="site-footer-col">
        <h5 class="site-footer-title">实验室</h5>
        
          <span class="site-footer-item">
            <a href="https://github.com/dongyuanxin/music-api-next" target="_blank">Music API</a>
          </span>
        
          <span class="site-footer-item">
            <a href="https://github.com/dongyuanxin/webpack-demos" target="_blank">Webpack4 Demos</a>
          </span>
        
          <span class="site-footer-item">
            <a href="https://github.com/dongyuanxin/theme-bmw" target="_blank">Theme bmw</a>
          </span>
        
          <span class="site-footer-item">
            <a href="https://github.com/dongyuanxin/news-emotion" target="_blank">金融情感分析模型</a>
          </span>
        
      </div>
    
      <div class="site-footer-col">
        <h5 class="site-footer-title">抓到我</h5>
        
          <span class="site-footer-item">
            <a href="https://juejin.im/user/5b91fcf06fb9a05d3c7fd4a5" target="_blank">掘金</a>
          </span>
        
          <span class="site-footer-item">
            <a href="https://segmentfault.com/" target="_blank">思否</a>
          </span>
        
          <span class="site-footer-item">
            <a href="https://www.jianshu.com/u/d1570f4a618a" target="_blank">简书</a>
          </span>
        
          <span class="site-footer-item">
            <a href="https://www.zhihu.com/people/godbmw/activities" target="_blank">知乎</a>
          </span>
        
      </div>
    
    <div class="site-footer-info">
      <i class="fa fa-clock-o"></i> 本站已稳定运行<span id="site-time"></span>
    </div>
    
      <div class="site-footer-info">
        <i class="fa fa-paw"></i> 您是本站第 <span id="site-count"></span> 位访客
      </div>
    
    <div class="site-footer-info">
      <i class="fa fa-at"></i> Email: yuanxin.me@gmail.com. QQ群: 534018786(主题交流)
    </div>
    <div class="site-footer-info">
      <i class="fa fa-copyright"></i> 
      2019 <a href="https://github.com/dongyuanxin/theme-ad/" target="_blank">Theme-AD</a>.
      Created by <a href="https:/godbmw.com/" target="_blank">GodBMW</a>.
      All rights reserved.
    </div>
  </footer>
</div>
    <div id="site-layer" style="display:none;">
  <div class="site-layer-content">
    <div class="site-layer-header">
      <span class="site-layer-header-title" id="site-layer-title"></span>
      <i class="fa fa-close" id="site-layer-close"></i>
    </div>
    <div class="site-layer-body" id="site-layer-container">
      <div class="site-layer-input" id="site-layer-search" style="display: none;">
        <input type="text">
        <i class="fa fa-search"></i>
      </div>
      <div class="site-layer-reward" id="site-layer-reward" style="display: none;">
        
          <div>
            <img src="/images/wechat.png" alt="WeChat">
            
              <p>WeChat</p>
            
          </div>
        
          <div>
            <img src="/images/alipay.png" alt="AliPay">
            
              <p>AliPay</p>
            
          </div>
        
      </div>
      <div id="site-layer-welcome" style="display:none;"></div>
    </div>
  </div>
</div>
    

<div class="bottom-bar">
  <div class="bottom-bar-left">
    <a href="javascript:void(0);" data-enable="false">
      <i class="fa fa-arrow-left"></i>
    </a>
    <a href="/2017/07/04/Scrapy爬取股票数据/" data-enable="true">
      <i class="fa fa-arrow-right"></i>
    </a>
  </div>
  <div class="bottom-bar-right">
    <a href="javascript:void(0);" data-enable="true" id="site-toc-show-btn">
      <i class="fa fa-bars"></i>
    </a>
    
      <a href="#site-comment" data-enable="true">
        <i class="fa fa-commenting"></i>
      </a>
    
    <a href="javascript:void(0);" id="site-toggle-share-btn">
      <i class="fa fa-share-alt"></i>
    </a>
    <a href="javascript:void(0);" id="site-reward">
      <i class="fa fa-thumbs-up"></i>
    </a>
    <a href="javascript:void(0);" id="back-top-btn">
      <i class="fa fa-chevron-up"></i>
    </a>
  </div>
</div>
    <div id="share-btn">
  
    <a id="share-btn-twitter" href="javascript:void(0);" target="_blank">
      <i class="fa fa-twitter"></i>
    </a>
  
  
    <a id="share-btn-facebook" href="javascript:void(0);" target="_blank">
      <i class="fa fa-facebook"></i>
    </a>
  
  
    <a id="share-btn-weibo" href="javascript:void(0);" target="_blank">
      <i class="fa fa-weibo"></i>
    </a>
  
  
    <a id="share-btn-qq" href="javascript:void(0);" target="_blank">
      <i class="fa fa-qq"></i>
    </a>
  
  
    <a id="share-btn-wechat" href="javascript:void(0);" target="_blank">
      <i class="fa fa-wechat"></i>
    </a>
  
</div>
  <script src="/live2dw/lib/L2Dwidget.min.js?0c58a1486de42ac6cc1c59c7d98ae887"></script><script>L2Dwidget.init({"model":{"jsonPath":"/live2dw/assets/miku.model.json"},"display":{"position":"right","width":150,"height":300},"mobile":{"show":true},"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>
</html>