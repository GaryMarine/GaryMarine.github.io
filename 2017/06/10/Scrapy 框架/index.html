<!DOCTYPE html>
<html>
  
<head>
  <meta charset="utf-8">
  <meta name="author" content="GaryMarine" />
  
  
  <title>Scrapy 框架 | GaryMarine</title>

  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

  
    <meta name="keywords" content="Python,Scrapy," />
  

  
  <meta name="description" content="GaryMarine Website">

  

  <script src="//cdn.jsdelivr.net/npm/leancloud-storage@3.11.1/dist/av-min.js" async></script>

  
    <script type="text/javascript" src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script>
  

  
    <script src="//unpkg.com/valine/dist/Valine.min.js" async></script>
  

  <script>
  // theme-ad's config script
  // it can be used in every script
  
  window.AD_CONFIG = {
    leancloud: {"appid":"Hyq9wkH495DgNHWhDQCOfQSp-gzGzoHsz","appkey":"WaR7nrzhliHj9aVwdQzkdlGd","comment":true,"count":true},
    welcome: {"enable":true,"interval":"wfw"},
    start_time: "2018-02-10",
    passwords: ["9fd4703ff67642ec7fc0f8616d7513e620263fa6f3758b5836f496dfe334ae34", ],
    is_post: true,
    lock: false,
    author: "GaryMarine",
    share: {"twitter":true,"facebook":true,"weibo":true,"qq":true,"wechat":true},
    mathjax: true
  };
</script>

  <script src="/vendor/sha256.min.js"></script>
<script src="/js/auth.js"></script>
<script src="/js/index.js"></script>
<script src="/vendor/qrcode.min.js"></script>

  
    <link rel="icon" href="/images/favicon.ico">
    <link rel="apple-touch-icon" href="/images/touch-icon.png">
  

  <link href="//netdna.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet">

  <link rel="stylesheet" href="/css/index.css">
<link rel="stylesheet" href="/styles/components/highlight/highlight.css">

  

  



</head>
  <body>
    <header class="site-header">
  <div class="site-header-brand">
    
      <span class="site-header-brand-title">
        <a href="/">GaryMarine</a>
      </span>
    
    
      <span class="site-header-brand-motto"> | 晚来天欲雪，能饮一杯无？</span>
    
  </div>
  <div class="site-header-right">
    <nav class="site-header-navigation">
      
        <a href="/" target="_self">首页</a>
      
        <a href="/archives/" target="_self">归档</a>
      
        <a href="/tags/" target="_self">标签</a>
      
        <a href="/categories/" target="_self">分类</a>
      
        <a href="/friends/" target="_self">友链</a>
      
        <a href="/about/" target="_self">关于</a>
      
    </nav>
    <div class="site-header-btn">
      
        <a href="https://github.com/GaryMarine/" target="_blank">
          <i class="fa fa-github-alt"></i>
        </a>
      
      <a href="javascript:void(0);" id="site-search">
        <i class="fa fa-search"></i>
      </a>
    </div>
  </div>
</header>
<div id="site-process"></div>
    <main>
      
  <div class="passage">
  <div class="passage-meta">
    <span>
      <i class="fa fa-calendar"></i>2017-06-10
    </span>
    
      <span>
        | <a href="/categories/Python/"><i class="fa fa-bookmark"></i>Python</a>
      </span>
    
    
      <span>
        | <i class="fa fa-unlock-alt"></i>UNLOCK
      </span>
    
  </div>
  <h1 class="passage-title">
    Scrapy 框架
  </h1>
  
  <article class="passage-article">
    <h1 id="Scrapy-框架"><a href="#Scrapy-框架" class="headerlink" title="Scrapy 框架"></a>Scrapy 框架</h1><ul>
<li>Scrapy是用纯Python实现一个为了爬取网站数据、提取结构性数据而编写的应用框架，用途非常广泛。</li>
<li>框架的力量，用户只需要定制开发几个模块就可以轻松的实现一个爬虫，用来抓取网页内容以及各种图片，非常方便。</li>
<li>Scrapy 使用了 Twisted(其主要对手是Tornado)多线程异步网络框架来处理网络通讯，可以加快我们的下载速度，不用自己去实现异步框架，并且包含了各种中间件接口，可以灵活的完成各种需求。</li>
</ul>
<h1 id="Scrapy架构图-绿线是数据流向"><a href="#Scrapy架构图-绿线是数据流向" class="headerlink" title="Scrapy架构图(绿线是数据流向)"></a>Scrapy架构图(绿线是数据流向)</h1><p><img src="D:\F\Project\Marine\day07\scrapy数据流向.png" alt="image"></p>
<ul>
<li>Scrapy Engine(引擎): 负责Spider、ItemPipeline、Downloader、Scheduler中间的通讯，信号、数据传递等。</li>
<li><code>Scheduler(调度器)</code>: 它负责接受<code>引擎</code>发送过来的Request请求，并按照一定的方式进行整理排列，入队，当<code>引擎</code>需要时，交还给<code>引擎</code>。</li>
<li><code>Downloader（下载器）</code>：负责下载<code>Scrapy Engine(引擎)</code>发送的所有Requests请求，并将其获取到的Responses交还给<code>Scrapy Engine(引擎)</code>，由<code>引擎</code>交给<code>Spider</code>来处理。</li>
<li><code>Spider（爬虫）</code>：它负责处理所有Responses,从中分析提取数据，获取Item字段需要的数据，并将需要跟进的URL提交给<code>引擎</code>，再次进入<code>Scheduler(调度器)</code>。</li>
<li><code>Item Pipeline(管道)</code>：它负责处理<code>Spider</code>中获取到的Item，并进行进行后期处理（详细分析、过滤、存储等）的地方。</li>
<li><code>Downloader Middlewares（下载中间件）</code>：你可以当作是一个可以自定义扩展下载功能的组件。</li>
<li><code>Spider Middlewares（Spider中间件）</code>：你可以理解为是一个可以自定扩展和操作<code>引擎</code>和<code>Spider</code>中间<code>通信</code>的功能组件（比如进入<code>Spider</code>的Responses;和从<code>Spider</code>出去的Requests）</li>
</ul>
<h1 id="Scrapy的运作流程"><a href="#Scrapy的运作流程" class="headerlink" title="Scrapy的运作流程"></a>Scrapy的运作流程</h1><p>代码写好，程序开始运行…</p>
<ol>
<li><code>引擎</code>：Hi！<code>Spider</code>, 你要处理哪一个网站？</li>
<li><code>Spider</code>：老大要我处理xxx.com。</li>
<li><code>引擎</code>：你把第一个需要处理的URL给我吧。</li>
<li><code>Spider</code>：给你，第一个URL是xxxxxxx.com。</li>
<li><code>引擎</code>：Hi！<code>调度器</code>，我这有request请求你帮我排序入队一下。</li>
<li><code>调度器</code>：好的，正在处理你等一下。</li>
<li><code>引擎</code>：Hi！<code>调度器</code>，把你处理好的request请求给我。</li>
<li><code>调度器</code>：给你，这是我处理好的request。</li>
<li><code>引擎</code>：Hi！下载器，你按照老大的<code>下载中间件</code>的设置帮我下载一下这个request请求。</li>
<li><code>下载器</code>：好的！给你，这是下载好的东西。（如果失败：sorry，这个request下载失败了。然后<code>引擎</code>告诉<code>调度器</code>，这个request下载失败了，你记录一下，我们待会儿再下载）</li>
<li><code>引擎</code>：Hi！<code>Spider</code>，这是下载好的东西，并且已经按照老大的<code>下载中间件</code>处理过了，你自己处理一下（注意！这儿responses默认是交给<code>def parse()</code>这个函数处理的）</li>
<li><code>Spider</code>：（处理完毕数据之后对于需要跟进的URL），Hi！<code>引擎</code>，我这里有两个结果，这个是我需要跟进的URL，还有这个是我获取到的Item数据。</li>
<li><code>引擎</code>：Hi ！<code>管道</code>我这儿有个item你帮我处理一下！<code>调度器</code>！这是需要跟进URL你帮我处理下。然后从第四步开始循环，直到获取完老大需要全部信息。</li>
<li><code>管道`</code>调度器`：好的，现在就做！</li>
</ol>
<p><strong>注意！只有当</strong><code>调度器</code><strong>中不存在任何request了，整个程序才会停止，（也就是说，对于下载失败的URL，Scrapy也会重新下载。）</strong></p>
<h1 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">1</span>、安装wheel</span><br><span class="line">pip install wheel</span><br><span class="line"></span><br><span class="line"><span class="number">2</span>、安装lxml</span><br><span class="line">pip install lxml</span><br><span class="line"></span><br><span class="line"><span class="number">3</span>、安装pyopenssl</span><br><span class="line">pip install pyopenssl</span><br><span class="line"></span><br><span class="line"><span class="number">4</span>、安装Twisted</span><br><span class="line">①从 http://www.lfd.uci.edu/~gohlke/pythonlibs/ Ctrl + F 输入Twisted下载</span><br><span class="line">②把下载好的文件放到python3<span class="number">.6</span>安装目录下的Scripts目录下，然后Shift+鼠标右键此处打开命令行，运行pip install Twisted + Tab键自动补全</span><br><span class="line"></span><br><span class="line"><span class="number">5</span>、安装pywin32</span><br><span class="line">pip install pywin32</span><br><span class="line"></span><br><span class="line"><span class="number">6</span>、安装scrapy</span><br><span class="line">pip install scrapy</span><br></pre></td></tr></table></figure>
<h1 id="Scrapy官网"><a href="#Scrapy官网" class="headerlink" title="Scrapy官网"></a>Scrapy官网</h1><p>Scrapy框架官方网址：<a href="https://legacy.gitbook.com/book/fategithub/pythonspider/edit#" target="_blank" rel="noopener">http://doc.scrapy.org/en/latest</a></p>
<p>Scrapy中文维护站点：<a href="https://legacy.gitbook.com/book/fategithub/pythonspider/edit#" target="_blank" rel="noopener">http://scrapy-chs.readthedocs.io/zh_CN/latest/index.html</a></p>
<h3 id="Ubuntu-需要9-10或以上版本安装方式"><a href="#Ubuntu-需要9-10或以上版本安装方式" class="headerlink" title="Ubuntu 需要9.10或以上版本安装方式"></a>Ubuntu 需要9.10或以上版本安装方式</h3><ul>
<li><p>Python 2 / 3</p>
</li>
<li><p>安装非Python的依赖</p>
<p><code>sudo apt-get install python-dev python-pip libxml2-dev libxslt1-dev zlib1g-dev libffi-dev libssl-dev</code></p>
</li>
<li><p>通过pip 安装 Scrapy 框架</p>
<p><code>sudo pip install scrapy</code></p>
</li>
</ul>
<p>安装后，只要在命令终端输入 scrapy，提示类似以下结果，代表已经安装成功</p>
<p>具体Scrapy安装流程参考：<a href="http://doc.scrapy.org/en/latest/intro/install.html#intro-install-platform-notes里面有各个平台的安装方法" target="_blank" rel="noopener">http://doc.scrapy.org/en/latest/intro/install.html#intro-install-platform-notes里面有各个平台的安装方法</a></p>
<h1 id="Scrapy-爬虫-一共需要4步："><a href="#Scrapy-爬虫-一共需要4步：" class="headerlink" title="Scrapy 爬虫 一共需要4步："></a>Scrapy 爬虫 一共需要4步：</h1><ul>
<li>新建项目 (scrapy startproject xxx)：新建一个新的爬虫项目</li>
<li>明确目标 （编写items.py）：明确你想要抓取的目标</li>
<li>制作爬虫 （spiders/xxspider.py）：制作爬虫开始爬取网页</li>
<li>存储内容 （pipelines.py）：设计管道存储爬取内容</li>
</ul>
<h1 id="入门案例"><a href="#入门案例" class="headerlink" title="入门案例"></a>入门案例</h1><ul>
<li>创建一个Scrapy项目</li>
<li>定义提取的结构化数据(Item)</li>
<li>编写爬取网站的 Spider 并提取出结构化数据(Item)</li>
<li>编写 Item Pipelines 来存储提取到的Item(即结构化数据)</li>
</ul>
<h2 id="一-新建项目-scrapy-startproject"><a href="#一-新建项目-scrapy-startproject" class="headerlink" title="一. 新建项目(scrapy startproject)"></a>一. 新建项目(scrapy startproject)</h2><ul>
<li>在开始爬取之前，必须创建一个新的Scrapy项目。进入自定义的项目目录中，运行下列命令：</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scrapy startproject mySpider</span><br></pre></td></tr></table></figure>
<ul>
<li>其中， mySpider 为项目名称，可以看到将会创建一个 mySpider 文件夹，目录结构大致如下：</li>
</ul>
<p><img src="D:\F\Project\Marine\day07\scrapy项目结构.png" alt="img"></p>
<p>下面来简单介绍一下各个主要文件的作用：</p>
<blockquote>
<p>scrapy.cfg ：项目的配置文件</p>
<p>mySpider/ ：项目的Python模块，将会从这里引用代码</p>
<p>mySpider/items.py ：项目的目标文件</p>
<p>mySpider/pipelines.py ：项目的管道文件</p>
<p>mySpider/settings.py ：项目的设置文件</p>
<p>mySpider/spiders/ ：存储爬虫代码目录</p>
</blockquote>
<h2 id="二、明确目标-mySpider-items-py"><a href="#二、明确目标-mySpider-items-py" class="headerlink" title="二、明确目标(mySpider/items.py)"></a>二、明确目标(mySpider/items.py)</h2><p>我们打算抓取：<a href="http://bbs.tianya.cn/post-140-393968-1.shtml" target="_blank" rel="noopener">http://bbs.tianya.cn/post-140-393968-1.shtml</a> 网站里的邮箱。</p>
<ol>
<li>打开mySpider目录下的items.py</li>
<li>Item 定义结构化数据字段，用来保存爬取到的数据，有点像Python中的dict，但是提供了一些额外的保护减少错误。</li>
<li>可以通过创建一个 scrapy.Item 类， 并且定义类型为 scrapy.Field的类属性来定义一个Item（可以理解成类似于ORM的映射关系）。</li>
<li>接下来，创建一个TianyaItem类，和构建item模型（model）。</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">TianyaItem</span><span class="params">(scrapy.Item)</span>:</span></span><br><span class="line">    email = scrapy.Field()</span><br></pre></td></tr></table></figure>
<h2 id="三、制作爬虫-（spiders-itcastSpider-py）"><a href="#三、制作爬虫-（spiders-itcastSpider-py）" class="headerlink" title="三、制作爬虫 （spiders/itcastSpider.py）"></a>三、制作爬虫 （spiders/itcastSpider.py）</h2><p><strong>爬虫功能要分两步：</strong></p>
<h3 id="1-爬数据"><a href="#1-爬数据" class="headerlink" title="1. 爬数据"></a>1. 爬数据</h3><ul>
<li>在当前目录下输入命令</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scrapy genspider mytianya <span class="string">"bbs.tianya.cn"</span></span><br></pre></td></tr></table></figure>
<ul>
<li>打开 mySpider/spider目录里的 mytianya .py，默认增加了下列代码:</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">from</span> tianya <span class="keyword">import</span> items</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MytianyaSpider</span><span class="params">(scrapy.Spider)</span>:</span></span><br><span class="line">    name = <span class="string">'mytianya'</span></span><br><span class="line">    allowed_domains = [<span class="string">'bbs.tianya.cn'</span>]</span><br><span class="line">    start_urls = [<span class="string">'http://bbs.tianya.cn/post-140-393977-1.shtml'</span>]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span><span class="params">(self, response)</span>:</span></span><br><span class="line">        <span class="keyword">pass</span></span><br></pre></td></tr></table></figure>
<p>其实也可以由我们自行创建itcast.py并编写上面的代码，只不过使用命令可以免去编写固定代码的麻烦；</p>
<p>要建立一个Spider， 你必须用scrapy.Spider类创建一个子类，并确定了三个强制的属性 和 一个方法。</p>
<ul>
<li><code>name = &quot;&quot;</code>：这个爬虫的识别名称，必须是唯一的，在不同的爬虫必须定义不同的名字。</li>
<li><code>allow_domains = []</code>是搜索的域名范围，也就是爬虫的约束区域，规定爬虫只爬取这个域名下的网页，不存在的URL会被忽略。</li>
<li><code>start_urls = ()</code>：爬取的URL元祖/列表。爬虫从这里开始抓取数据，所以，第一次下载的数据将会从这些urls开始。其他子URL将会从这些起始URL中继承性生成。</li>
<li><code>parse(self, response)</code>：解析的方法，每个初始URL完成下载后将被调用，调用的时候传入从每一个URL传回的Response对象来作为唯一参数，主要作用如下：<ol>
<li>负责解析返回的网页数据(response.body)，提取结构化数据(生成item)</li>
<li>生成需要下一页的URL请求。</li>
</ol>
</li>
<li>将start_urls的值修改为需要爬取的第一个url</li>
</ul>
<h5 id="修改parse-方法"><a href="#修改parse-方法" class="headerlink" title="修改parse()方法"></a>修改parse()方法</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">parse</span><span class="params">(self, response)</span>:</span></span><br><span class="line">    html = response.body.decode()</span><br><span class="line">    <span class="comment"># ftsd@21cn.com</span></span><br><span class="line">    email = re.compile(<span class="string">r"([A-Z0-9_]+@[A-Z0-9]+\.[A-Z]&#123;2,4&#125;)"</span>, re.I)</span><br><span class="line">    emailList = email.findall(html)</span><br><span class="line">    mydict = []</span><br><span class="line">    <span class="keyword">for</span> e <span class="keyword">in</span> emailList:</span><br><span class="line">        item = items.TianyaItem()</span><br><span class="line">        item[<span class="string">"email"</span>] = e</span><br><span class="line">        <span class="comment"># mydict[e] = "http://bbs.tianya.cn/post-140-393977-1.shtml"</span></span><br><span class="line">        mydict.append(item)</span><br><span class="line">    <span class="keyword">return</span> mydict</span><br></pre></td></tr></table></figure>
<p>然后运行一下看看，在mySpider目录下执行：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scrapy crawl mytianya</span><br></pre></td></tr></table></figure>
<h2 id="2-保存数据"><a href="#2-保存数据" class="headerlink" title="2.保存数据"></a>2.保存数据</h2><h5 id="scrapy保存信息的最简单的方法主要有四种，-o-输出指定格式的文件，命令如下："><a href="#scrapy保存信息的最简单的方法主要有四种，-o-输出指定格式的文件，命令如下：" class="headerlink" title="scrapy保存信息的最简单的方法主要有四种，-o 输出指定格式的文件，命令如下："></a>scrapy保存信息的最简单的方法主要有四种，-o 输出指定格式的文件，命令如下：</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">scrapy crawl mytianya -o mytianya.json</span><br><span class="line"></span><br><span class="line">scrapy crawl mytianya -o mytianya.csv</span><br><span class="line"></span><br><span class="line">scrapy crawl mytianya -o mytianya.xml</span><br></pre></td></tr></table></figure>
<h4 id="如果将代码改成下面形式，结果完全一样。"><a href="#如果将代码改成下面形式，结果完全一样。" class="headerlink" title="如果将代码改成下面形式，结果完全一样。"></a>如果将代码改成下面形式，结果完全一样。</h4><h4 id="yield-在这里的作用？"><a href="#yield-在这里的作用？" class="headerlink" title="yield 在这里的作用？"></a>yield 在这里的作用？</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">parse</span><span class="params">(self, response)</span>:</span></span><br><span class="line">    html = response.body.decode()</span><br><span class="line">    <span class="comment"># ftsd@21cn.com</span></span><br><span class="line">    email = re.compile(<span class="string">r"([A-Z0-9_]+@[A-Z0-9]+.[A-Z]&#123;2,4&#125;)"</span>, re.I)</span><br><span class="line">    emailList = email.findall(html)</span><br><span class="line">    mydict = []</span><br><span class="line">    <span class="keyword">for</span> e <span class="keyword">in</span> emailList:</span><br><span class="line">        item = items.TianyaItem()</span><br><span class="line">        item[<span class="string">"email"</span>] = e</span><br><span class="line">        <span class="comment"># mydict[e] = "http://bbs.tianya.cn/post-140-393977-1.shtml"</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># mydict.append(item)</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">#将获取的数据交给pipelines</span></span><br><span class="line">        <span class="keyword">yield</span> mydict</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 返回数据，不经过pipeline</span></span><br><span class="line">    <span class="keyword">return</span> mydict</span><br></pre></td></tr></table></figure>
  </article>
  <aside class="table-content" id="site-toc">
  <div class="table-content-title">
    <i class="fa fa-arrow-right fa-lg" id="site-toc-hide-btn"></i>
    <span>目录</span>
  </div>
  <div class="table-content-main">
    <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Scrapy-框架"><span class="toc-text">Scrapy 框架</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Scrapy架构图-绿线是数据流向"><span class="toc-text">Scrapy架构图(绿线是数据流向)</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Scrapy的运作流程"><span class="toc-text">Scrapy的运作流程</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#安装"><span class="toc-text">安装</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Scrapy官网"><span class="toc-text">Scrapy官网</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Ubuntu-需要9-10或以上版本安装方式"><span class="toc-text">Ubuntu 需要9.10或以上版本安装方式</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Scrapy-爬虫-一共需要4步："><span class="toc-text">Scrapy 爬虫 一共需要4步：</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#入门案例"><span class="toc-text">入门案例</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#一-新建项目-scrapy-startproject"><span class="toc-text">一. 新建项目(scrapy startproject)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#二、明确目标-mySpider-items-py"><span class="toc-text">二、明确目标(mySpider/items.py)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#三、制作爬虫-（spiders-itcastSpider-py）"><span class="toc-text">三、制作爬虫 （spiders/itcastSpider.py）</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-爬数据"><span class="toc-text">1. 爬数据</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#修改parse-方法"><span class="toc-text">修改parse()方法</span></a></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-保存数据"><span class="toc-text">2.保存数据</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#scrapy保存信息的最简单的方法主要有四种，-o-输出指定格式的文件，命令如下："><span class="toc-text">scrapy保存信息的最简单的方法主要有四种，-o 输出指定格式的文件，命令如下：</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#如果将代码改成下面形式，结果完全一样。"><span class="toc-text">如果将代码改成下面形式，结果完全一样。</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#yield-在这里的作用？"><span class="toc-text">yield 在这里的作用？</span></a></li></ol></li></ol></li></ol></li></ol>
  </div>
</aside>
  
    <div class="passage-tags">
     
      <a href="/tags/Scrapy/"><i class="fa fa-tags"></i>Scrapy</a>
    
    </div>
  
</div>

    </main>
    
      <div class="site-comment-contanier">
  <p id="site-comment-info">
    <i class="fa fa-spinner fa-spin"></i> 评论加载中
  </p>
  <div id="site-comment">
  </div>
</div>
    
    <div class="site-footer-wrapper">
  <footer class="site-footer">
    
      <div class="site-footer-col">
        <h5 class="site-footer-title">站点推荐</h5>
        
          <span class="site-footer-item">
            <a href="https://lidx.club/" target="_blank">GaryMarine</a>
          </span>
        
          <span class="site-footer-item">
            <a href="http://ruanyifeng.com/" target="_blank">阮一峰的个人网站</a>
          </span>
        
          <span class="site-footer-item">
            <a href="https://www.liaoxuefeng.com/" target="_blank">廖雪峰的官方网站</a>
          </span>
        
          <span class="site-footer-item">
            <a href="https://36kr.com/" target="_blank">36氪_让一部分人先看到未来</a>
          </span>
        
      </div>
    
      <div class="site-footer-col">
        <h5 class="site-footer-title">抓到我</h5>
        
          <span class="site-footer-item">
            <a href="https://music.163.com/#/my/m/music/playlist?id=385505488" target="_blank">音乐</a>
          </span>
        
          <span class="site-footer-item">
            <a href="https://www.zhihu.com/people/gu-hu-31-87/activities" target="_blank">知乎</a>
          </span>
        
          <span class="site-footer-item">
            <a href="https://weibo.com/5092313013/profile?rightmod=1&wvr=6&mod=personinfo&is_all=1 " target="_blank">微博</a>
          </span>
        
      </div>
    
    <div class="site-footer-info">
      <i class="fa fa-clock-o"></i> 本站已稳定运行<span id="site-time"></span>
    </div>
    
      <div class="site-footer-info">
        <i class="fa fa-paw"></i> 您是本站第 <span id="site-count"></span> 位访客
      </div>
    
    <div class="site-footer-info">
      <i class="fa fa-at"></i> Email: yuanxin.me@gmail.com. QQ群: 534018786(主题交流)
    </div>
    <div class="site-footer-info">
      <i class="fa fa-copyright"></i> 
      2019 <a href="https://github.com/dongyuanxin/theme-ad/" target="_blank">Theme-AD</a>.
      Created by <a href="https:/godbmw.com/" target="_blank">GodBMW</a>.
      All rights reserved.
    </div>
  </footer>
</div>
    <div id="site-layer" style="display:none;">
  <div class="site-layer-content">
    <div class="site-layer-header">
      <span class="site-layer-header-title" id="site-layer-title"></span>
      <i class="fa fa-close" id="site-layer-close"></i>
    </div>
    <div class="site-layer-body" id="site-layer-container">
      <div class="site-layer-input" id="site-layer-search" style="display: none;">
        <input type="text">
        <i class="fa fa-search"></i>
      </div>
      <div class="site-layer-reward" id="site-layer-reward" style="display: none;">
        
          <div>
            <img src="/images/wechat.png" alt="WeChat">
            
              <p>WeChat</p>
            
          </div>
        
          <div>
            <img src="/images/alipay.png" alt="AliPay">
            
              <p>AliPay</p>
            
          </div>
        
      </div>
      <div id="site-layer-welcome" style="display:none;"></div>
    </div>
  </div>
</div>
    

<div class="bottom-bar">
  <div class="bottom-bar-left">
    <a href="/2017/06/23/urllib/" data-enable="true">
      <i class="fa fa-arrow-left"></i>
    </a>
    <a href="/2017/06/06/Python与Redis的交互+Redis事务/" data-enable="true">
      <i class="fa fa-arrow-right"></i>
    </a>
  </div>
  <div class="bottom-bar-right">
    <a href="javascript:void(0);" data-enable="true" id="site-toc-show-btn">
      <i class="fa fa-bars"></i>
    </a>
    
      <a href="#site-comment" data-enable="true">
        <i class="fa fa-commenting"></i>
      </a>
    
    <a href="javascript:void(0);" id="site-toggle-share-btn">
      <i class="fa fa-share-alt"></i>
    </a>
    <a href="javascript:void(0);" id="site-reward">
      <i class="fa fa-thumbs-up"></i>
    </a>
    <a href="javascript:void(0);" id="back-top-btn">
      <i class="fa fa-chevron-up"></i>
    </a>
  </div>
</div>
    <div id="share-btn">
  
    <a id="share-btn-twitter" href="javascript:void(0);" target="_blank">
      <i class="fa fa-twitter"></i>
    </a>
  
  
    <a id="share-btn-facebook" href="javascript:void(0);" target="_blank">
      <i class="fa fa-facebook"></i>
    </a>
  
  
    <a id="share-btn-weibo" href="javascript:void(0);" target="_blank">
      <i class="fa fa-weibo"></i>
    </a>
  
  
    <a id="share-btn-qq" href="javascript:void(0);" target="_blank">
      <i class="fa fa-qq"></i>
    </a>
  
  
    <a id="share-btn-wechat" href="javascript:void(0);" target="_blank">
      <i class="fa fa-wechat"></i>
    </a>
  
</div>
  <script src="/live2dw/lib/L2Dwidget.min.js?0c58a1486de42ac6cc1c59c7d98ae887"></script><script>L2Dwidget.init({"model":{"jsonPath":"/live2dw/assets/miku.model.json"},"display":{"position":"right","width":150,"height":300},"mobile":{"show":true},"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>
</html>